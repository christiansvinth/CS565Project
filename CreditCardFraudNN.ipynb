{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.35980713 -0.07278117  2.53634674  1.37815522 -0.33832077  0.46238778\n",
      "  0.23959855  0.0986979   0.36378697  0.09079417 -0.55159953 -0.61780086\n",
      " -0.99138985 -0.31116935  1.46817697 -0.47040053  0.20797124  0.02579058\n",
      "  0.40399296  0.2514121  -0.01830678  0.27783758 -0.11047391  0.06692807\n",
      "  0.12853936 -0.18911484  0.13355838 -0.02105305  0.24496426] 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0941979355526301"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactionData = cc_data.drop(['Time'], axis=1)\n",
    "transactionData['Amount'] = StandardScaler().fit_transform(transactionData['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "X = transactionData.drop(\"Class\", axis=1).values\n",
    "y = transactionData['Class'].values\n",
    "assert(len(X) == len(y))\n",
    "print(X[0], y[2])\n",
    "#print(y)\n",
    "\n",
    "np.var(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.as_tensor(X)\n",
    "y_tensor = torch.as_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([284807, 29])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(29, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = binaryClassification().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionData = cc_data.drop(['Time'], axis=1)\n",
    "transactionData['Amount'] = StandardScaler().fit_transform(transactionData['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56962\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "minibatch_size = 32\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymemcache.client import base\n",
    "from pymemcache import serde\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import random\n",
    "import heapq\n",
    "        \n",
    "class RemoteCacheSampler(Sampler):\n",
    "    def __init__(self, dataset):\n",
    "        # not efficient but keep copy of dataset in sampler\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        # create generator, which allows us to iterate over the dataset once and only once\n",
    "        seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "        self.generator=torch.Generator()\n",
    "        self.generator.manual_seed(seed)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # should return an iterator over dataset\n",
    "        for g in torch.randperm(len(train_data), generator=self.generator).tolist():\n",
    "            yield g\n",
    "            \n",
    "    def __len__(self):\n",
    "        # returns number of rows in dataframe\n",
    "        return len(self.dataset)\n",
    "    \n",
    "class RemoteCacheDataset(Dataset):\n",
    "    def __init__(self, *tensors, data_variance):\n",
    "        # set client for memcached\n",
    "        # this sets the port to 11211 and also crucially adds a serializer\n",
    "        self.client =  base.Client((\"localhost\", 11211), serde=serde.pickle_serde) # client connection gets set up with default values for now\n",
    "\n",
    "        # shadow cache is a heap with the following format:\n",
    "        #    [<count of uses>, <item index in original dataset>]\n",
    "        self.shadow_cache = []\n",
    "        self.cache_size = 32\n",
    "        # this keeps the overall data variance and is used for scaling determination\n",
    "        # cache variance keeps track of the current variance of the cache\n",
    "        self._data_variance = data_variance\n",
    "        self._cache_variance = 0\n",
    "        self.tensors = tensors\n",
    "        self.size = tensors[0].size(0)\n",
    "        \n",
    "        # initially seed memcached server with X number of values\n",
    "        for i in range(self.cache_size):\n",
    "            self._write_cache(i, [tensors[0][i].tolist(), tensors[1][i].tolist()])\n",
    "            heapq.heappush(self.shadow_cache, [1, i])\n",
    "            \n",
    "        # compute cache variance - used for scaling sample from cache\n",
    "        self._compute_cache_variance()\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._query_cache(index)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def _query_cache(self, index):\n",
    "        result = self.client.get(str(index))\n",
    "        \n",
    "        if result is None:\n",
    "            # if we get a cache miss we need to perform the following operations:\n",
    "            #    1) select a random index in the queue\n",
    "            #    2) update the counter of the selected index to be the largest in the queue\n",
    "            #    3) evict LRU item and fetch the new item - should also increase its index so it won't\n",
    "            #       immediately get evicted from the cache\n",
    "            #    4) compute updated cache variance\n",
    "            substitue_index = random.randint(0, len(self.shadow_cache) - 1)\n",
    "            \n",
    "            largest_value = self.shadow_cache[self.cache_size-1][0]\n",
    "            self.shadow_cache[substitue_index][0] = largest_value + 1\n",
    "            # re-heapify in case we selected the least recently used item\n",
    "            heapq.heapify(self.shadow_cache)\n",
    "            \n",
    "            # get actual data from cache and scale - how to scale??\n",
    "            key_to_get = str(self.shadow_cache[substitue_index][1])\n",
    "            result = self.client.get(key_to_get)\n",
    "            # scale result by simple multiplication: this scale factor will likely be small given the initial\n",
    "            # variance of the overall dataset\n",
    "            print(result)\n",
    "            result = [(np.array(result[0]) * self._cache_variance/self._data_variance).tolist(), result[1]]\n",
    "            \n",
    "            #key_to_remove = random.sample(self.shadow_cache, 1)[0]\n",
    "            # according to heapq, this is more efficient than explicitly doing a push/pop operation\n",
    "            heapq.heappushpop(self.shadow_cache, [largest_value+2, index])\n",
    "            self._write_cache(index, [self.tensors[0][index].tolist(), self.tensors[1][index].tolist()])\n",
    "            \n",
    "            # lastly recompute updated cache variance\n",
    "            self._compute_cache_variance()\n",
    "\n",
    "        # result should now be in the form of a list with data as first item and output as second, \n",
    "        # convert to the format the model exepcts\n",
    "        item = tuple([torch.as_tensor(result[0]), torch.as_tensor(result[1])])\n",
    "        \n",
    "        return item\n",
    "    \n",
    "    def _write_cache(self, index, item):\n",
    "        # update remote cache.  Ideally this should be done on the server\n",
    "        # not the client, however that is a limitation of using memcached\n",
    "        self.client.set(str(index), item)\n",
    "        \n",
    "    def _compute_cache_variance(self):\n",
    "        # compute the current variance of the cache\n",
    "        # ideally this is something the cache server would do, however\n",
    "        # again due to limitations of using memcached, we perform this on the client side\n",
    "        temp_data = []\n",
    "        # slow and inefficient way to compute variance, but also easist to proof out\n",
    "        for i in range(self.cache_size):\n",
    "            temp_data.append(self.tensors[0][i].tolist())\n",
    "\n",
    "        temp_data = np.array(temp_data)\n",
    "        self._cache_variance = np.var(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0941979355526301\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=1)\n",
    "\n",
    "print(np.var(X))\n",
    "train_data = RemoteCacheDataset(X_train, y_train, data_variance=np.var(X))\n",
    "#print(type(train_data))\n",
    "#print(train_data[0], type(train_data[0]))\n",
    "#print(len(train_data), len(train_data[0]))\n",
    "test_data = TensorDataset(X_test)\n",
    "\n",
    "#seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "#print(seed, type(seed))\n",
    "#generator=torch.Generator()\n",
    "#generator.manual_seed(seed)\n",
    "#a = torch.randperm(len(train_data), generator=generator).tolist()\n",
    "#print(type(a))\n",
    "#print(a[:3])\n",
    "#print(train_data[a[0]])\n",
    "train_sampler = RemoteCacheSampler(train_data)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=minibatch_size, \n",
    "                          sampler=train_sampler)#shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "#print(train_loader, type(train_loader))\n",
    "#count = 0\n",
    "#for X_batch, y_batch in train_loader:\n",
    "#    print(count)\n",
    "#    count += 1\n",
    "#    print(type(X_batch), len(X_batch), X_batch)\n",
    "#    break\n",
    "    #print(\"X batch\",X_batch, type(X_batch))\n",
    "    #print(\"Y batch\",y_batch, type(y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-f5d326683222>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['train_loss'] = []\n",
    "history['test_loss'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0951049024200784, 0.957347058540245, -0.40883612266111796, -0.527176458477784, 0.9986340243259141, -0.8789404695889549, 0.914890166727169, -0.10177371573570099, -0.0376394047285783, -0.825499383097851, -0.714938831897266, -0.12436000518308801, 0.00370072740397579, -1.01344993760901, -0.233583579856413, 0.33699672022899896, 0.359413426547255, -0.20505670341311, -0.21852384390943103, 0.0368714625895726, -0.33767732538022494, -0.844743851886843, 0.10468184860850699, 0.5586217772858979, -0.415097596707234, 0.11380693472701801, 0.21988299283034698, 0.0855951636932077, -0.3460728186796746], 0]\n",
      "[[-2.17323594869766, 0.59825691485958, 1.20957245587291, -0.328127172205285, 0.331068175451033, 1.09334617972661, 0.307360892645115, 0.651999205536677, 0.460821898200986, -0.25293244504983803, 0.34015908581545695, 0.46573647869003104, -0.7340638975475551, -0.127522231322176, 0.4541596770373621, -1.39917399492748, 1.1729441962775, -2.67690342462987, -1.99040381957445, -0.374292242466957, -0.20396196832449398, -0.0103372995169139, 0.0127676576989132, -0.6093495286577709, 0.270084280179798, 0.27345954582422505, -0.23877051825356602, -0.21497522804366198, -0.12090060423708895], 0]\n",
      "[[-1.34166582084923, -0.41424467770374895, 0.6406773719302671, -0.592954000598554, 0.137885787575438, -0.0244606756599797, 0.8774938989464441, -0.244469508003303, 0.9380090284044351, 0.0547321036083648, 0.30652749897941495, -0.0447889342612199, -1.26303832324736, -0.0527625855821224, -0.18872562452513897, 0.384551135283428, -1.10989328034547, 0.516574056186141, 0.24168114050461398, -0.38044936386577005, -0.22961709677412398, -0.185436639634346, 0.0236292189773972, -0.520908101325861, -1.24575022521708, -0.905703098114271, -0.6934573177751852, -0.418434740420366, 0.20650267418449023], 0]\n",
      "[[0.0951049024200784, 0.957347058540245, -0.40883612266111796, -0.527176458477784, 0.9986340243259141, -0.8789404695889549, 0.914890166727169, -0.10177371573570099, -0.0376394047285783, -0.825499383097851, -0.714938831897266, -0.12436000518308801, 0.00370072740397579, -1.01344993760901, -0.233583579856413, 0.33699672022899896, 0.359413426547255, -0.20505670341311, -0.21852384390943103, 0.0368714625895726, -0.33767732538022494, -0.844743851886843, 0.10468184860850699, 0.5586217772858979, -0.415097596707234, 0.11380693472701801, 0.21988299283034698, 0.0855951636932077, -0.3460728186796746], 0]\n",
      "[[1.28784893714409, -0.538757014800753, 1.04351512972934, -0.574612611242361, -1.33706652964835, -0.684251690765444, -0.7917379873593821, -0.0727260252909244, -0.764422608258703, 0.521351496235386, 0.6329990271223779, 0.22701888673485898, 1.1431589106210702, -0.449431131302175, 1.08123429402494, 0.8968167144890531, 0.545320314374109, -2.00909353705416, -0.129245427113206, 0.11484081349357302, 0.16269123845013903, 0.43470646615853703, 0.13623550037621698, 0.63133863247459, 0.14449012460086802, -0.34158376451285993, 0.048004421577484996, 0.0321186336587016, -0.2724280709873375], 0]\n",
      "[[1.17091758208936, -0.11472439243460499, 0.554321381216344, -0.0928373702323096, -0.548225142368659, -0.517148279194, -0.16921654199579803, -0.0937435011280031, 0.23411394092643897, -0.30344036169176297, 0.16809988374292098, 0.847854594522473, 1.12768094762213, -0.034936025115377, 1.39728513568755, 0.0709082636685311, -0.14214488880322598, -0.9845747520615099, -0.348410216015922, 0.0414920593458825, -0.072786978128416, -0.19498337756641396, 0.0827389226420275, 0.166292307598435, 0.0656834897828684, 0.9268126107371841, -0.0544911211144126, 0.0145249645789196, -0.1996229213957273], 0]\n",
      "[[-0.67988246552354, 1.2593181194193999, 0.5584068261283011, 0.8935296446502429, 0.5821321620643071, 1.09730555264465, 0.136686335995424, 0.75644634264963, -0.655798822978515, -0.159487190485999, -0.237579936382292, 0.649660971018313, 0.21207876661986197, 0.416192169554433, -0.44410097792125397, -0.521847001235113, 0.0543107243655896, 0.26628832201825803, 1.51087941752302, 0.0753821314945101, -0.0304318924788424, 0.14174781338009101, -0.287917154122248, -1.3007726666216999, 0.0848708064096956, -0.155650739863165, 0.30162413100129903, 0.11833455318734698, -0.32928085666513524], 0]\n",
      "[[-0.10576640798232598, 0.934002903168249, -1.05887737262919, -0.209986316899576, 0.281317020045887, -0.8439184542602299, 0.6902063825195209, 0.308419898819812, -0.356870754426502, -1.0318316860205998, 0.555358347107329, -0.0927488392996441, -1.04802746366007, -0.103249373805889, 0.0826061808964262, 0.5187197654082439, 0.291197890308083, 1.48519073402802, 0.21064937779854398, -0.14008952043758402, 0.400890355584551, 0.9675476777910079, -0.0277816598968863, -0.437186253247247, -0.338340190993443, -0.151412317537328, -0.0351066966692458, 0.0276939347697707, -0.07344332111504541], 0]\n",
      "[[-0.4510362332161211, 1.49744347047555, -0.659458053359948, 0.8407811247236658, 0.995395115160583, -0.43580081689921996, 1.1231117266779398, 0.150450581393573, -0.862915317167963, -0.24895481202222797, -1.8202436576354097, 0.0990393685228532, 0.48033680552609703, 0.655623972508459, -0.360051925173826, -0.894357025380595, 0.0552721397018113, -0.141510809285462, 1.02853806954694, 0.0434972447982228, 0.12339324158690801, 0.55574305892468, -0.306768273169909, -0.7447862362991651, 0.17508044321121802, -0.32808321038312, 0.31367253751909197, 0.16895988812440602, -0.2614733148159475], 0]\n",
      "[[-3.27273241660343, -1.3432629444830901, 0.380179336180509, -3.2796679908829702, -3.0594261920090897, 0.43888277993957303, 0.529418653678293, 0.5164615767190871, 0.9291950818333459, -1.6002023472308, 0.860094940261195, 1.43571681272325, -0.229896618443839, -0.0602162180884286, -0.46787250660380697, -2.2200888207608998, 0.613357373268039, 1.3341219914853, 0.0824019275606322, -2.2025533770690604, -0.6969598564777421, -0.0971105213718155, 0.6225028901023001, 0.256883367678837, 0.30417263364646, -0.970753735835028, -0.0141199911110113, -0.32844341052179804, 1.145013427349486], 0]\n",
      "[[-2.1575680079556, -0.889883320039401, 0.515972480692211, -1.62307315774276, 0.9301334549970519, 1.5387890285189099, 1.80820481963754, -0.8280544515689391, -0.358611537246842, 0.944893502732745, -0.612672570624371, -1.1002557606413401, -0.4595711590910129, -0.677815201571098, 1.29770876320893, -2.64412121816949, 0.0671521256433598, 0.231696049270663, -1.73465831107945, -1.3997311308278, -0.42417960292523493, 0.752875907171328, -0.116875139092467, -0.530987528851443, 0.9082417593685078, 0.077053373073338, -0.955544829552287, -0.39223972125710904, 0.46637827679045735], 0]\n",
      "[[-1.68652104270816, -0.592009121278254, 2.0098613222077, -1.92047039398777, -0.29126220564144395, -0.45514747338595, 0.7869732842709871, -0.30048598565475704, 1.61015888352745, -1.51090348731369, -1.06848543785363, -0.0467279122653175, -0.320653564457761, -0.6538213670412509, 0.7589224825112951, -0.0536651021767561, -0.7989669059573621, 0.580737332717913, 0.0138473053982106, -0.462593438343701, -0.0201748996699252, 0.6949085654349481, 0.119627804513843, -0.0932991587737513, 0.8608512435630911, -0.635093512620157, -0.0928732250535704, -0.27454054257019894, 0.12654095030573112], 0]\n",
      "[[-0.67988246552354, 1.2593181194193999, 0.5584068261283011, 0.8935296446502429, 0.5821321620643071, 1.09730555264465, 0.136686335995424, 0.75644634264963, -0.655798822978515, -0.159487190485999, -0.237579936382292, 0.649660971018313, 0.21207876661986197, 0.416192169554433, -0.44410097792125397, -0.521847001235113, 0.0543107243655896, 0.26628832201825803, 1.51087941752302, 0.0753821314945101, -0.0304318924788424, 0.14174781338009101, -0.287917154122248, -1.3007726666216999, 0.0848708064096956, -0.155650739863165, 0.30162413100129903, 0.11833455318734698, -0.32928085666513524], 0]\n",
      "[[1.8537680120320201, 0.244379045726839, -2.3691053698770896, 1.4320603549648898, 0.949560938275124, -0.6434279527247889, 0.6383880448668579, -0.189466175667721, -0.0992428826417251, -0.215136125245522, 1.13504178986, 0.554778707854398, -0.6713953127945821, -0.7204422205111229, -0.985733796235881, -0.0192121203283783, 0.7851380438073249, 0.567028999877452, -0.17542939963391, -0.0982894546235418, 0.0526458138815434, 0.154805394273405, -0.0545155340172094, 0.576256829421178, 0.4106608675823571, -0.54824980273016, -0.0196795413646786, -0.0208557741459236, -0.052533330320749944], 0]\n",
      "[[0.118400028198084, 0.962813823100788, -0.570852291201514, -0.7563088903272299, 1.18916377999941, -0.254450412988251, 0.8912740608779691, 0.0521787583612518, -0.307331533080406, -0.674946793244659, 0.647110013176773, 0.524289822165538, 0.18673785073511898, -0.883092671874441, -0.927381620344302, 0.648388165564583, -0.0551415289711495, 0.402447464584627, 0.223450536855621, 0.071903185910092, -0.312351114128572, -0.7888150096174659, 0.0427274504908587, 0.0949363555827787, -0.38326429880041296, 0.121130141529845, 0.216724008062674, 0.070765294851277, -0.3159672296393218], 0]\n",
      "[[1.8537680120320201, 0.244379045726839, -2.3691053698770896, 1.4320603549648898, 0.949560938275124, -0.6434279527247889, 0.6383880448668579, -0.189466175667721, -0.0992428826417251, -0.215136125245522, 1.13504178986, 0.554778707854398, -0.6713953127945821, -0.7204422205111229, -0.985733796235881, -0.0192121203283783, 0.7851380438073249, 0.567028999877452, -0.17542939963391, -0.0982894546235418, 0.0526458138815434, 0.154805394273405, -0.0545155340172094, 0.576256829421178, 0.4106608675823571, -0.54824980273016, -0.0196795413646786, -0.0208557741459236, -0.052533330320749944], 0]\n",
      "[[2.08822462710787, -1.8225517872701698, -1.04699362579447, -1.71074451329445, -1.16430869345828, 0.156344549947887, -1.30445022733489, 0.0509695192539943, -1.2214567760031398, 1.6817046509103502, 0.116397540302804, -0.493192651670461, 0.119706855742806, -0.295737976657509, -0.63520522328701, -0.03195195233903, -0.00029268837966584, 0.7801490782361619, 0.252675457342555, -0.199803537256344, -0.0765643075565207, -0.00472587035662425, 0.13363922730076, 0.16751073382199802, -0.273573177323639, -0.20617940150557498, -0.00426552152749324, -0.0362612689803177, 0.11054860552997929], 0]\n",
      "[[0.118400028198084, 0.962813823100788, -0.570852291201514, -0.7563088903272299, 1.18916377999941, -0.254450412988251, 0.8912740608779691, 0.0521787583612518, -0.307331533080406, -0.674946793244659, 0.647110013176773, 0.524289822165538, 0.18673785073511898, -0.883092671874441, -0.927381620344302, 0.648388165564583, -0.0551415289711495, 0.402447464584627, 0.223450536855621, 0.071903185910092, -0.312351114128572, -0.7888150096174659, 0.0427274504908587, 0.0949363555827787, -0.38326429880041296, 0.121130141529845, 0.216724008062674, 0.070765294851277, -0.3159672296393218], 0]\n",
      "[[-0.77949006001487, -0.00334132862908323, 0.192250368413604, -0.8622394341048292, 1.3328916991956399, 4.08682150860979, -0.920311007363978, 1.5469106616133201, 0.179632122674954, -0.841902911238828, -0.8154572897535709, 0.18653742190710199, 0.0037115048048350797, -0.0980924096490342, 0.15995937457721, -0.148776786615928, 0.180522339838117, 0.17804951836374697, 1.93908171218483, 0.313503071956861, -0.0752039860147843, -0.402506916597976, 0.143608199010302, 1.0788485973795099, -0.47450522417521707, 1.0275184224470502, -0.0273719540441783, 0.0432668621469769, -0.06784600044353231], 0]\n",
      "[[1.17091758208936, -0.11472439243460499, 0.554321381216344, -0.0928373702323096, -0.548225142368659, -0.517148279194, -0.16921654199579803, -0.0937435011280031, 0.23411394092643897, -0.30344036169176297, 0.16809988374292098, 0.847854594522473, 1.12768094762213, -0.034936025115377, 1.39728513568755, 0.0709082636685311, -0.14214488880322598, -0.9845747520615099, -0.348410216015922, 0.0414920593458825, -0.072786978128416, -0.19498337756641396, 0.0827389226420275, 0.166292307598435, 0.0656834897828684, 0.9268126107371841, -0.0544911211144126, 0.0145249645789196, -0.1996229213957273], 0]\n",
      "[[2.11573844216447, -0.0247513917748374, -1.3665913367435403, 0.233705521335386, 0.27859829221989596, -0.768631778948294, 0.21122310287531498, -0.322502792146835, 0.49804744472111406, 0.05596967911049, -1.30670917470767, 0.524204451652364, 0.823338942468109, 0.10540899998473299, 0.0261415272194749, 0.0846787171009912, -0.597319778909787, -0.701281242321764, 0.42532604307743793, -0.159841545753356, -0.331499117386414, -0.786182037893091, 0.23972513913015897, -0.69861556820765, -0.176785236187567, 0.240467689649355, -0.0676151309141837, -0.0662164007057468, -0.3460728186796746], 0]\n",
      "[[-1.4339796318200901, 0.894810650978021, -0.889277200273744, 1.0111552876462, 0.786426569852317, -0.246248394901049, 0.777782822188757, 0.423475364407818, -1.06892949983211, -0.069875432443431, 0.422585379018814, 0.7756496275331078, -0.23039609695365001, 1.0962054407873598, -0.951406639787052, -0.7922162656312671, 0.14985219476544698, 0.205810947788142, 1.06955863406254, -0.198397619452524, 0.271375649046193, 0.669471449641657, -0.40340607751916496, 0.747546969965182, -0.104007267938767, -0.505611522892238, -0.43255062093179, -0.275208573157053, -0.12186014492363408], 0]\n",
      "[[1.19712589175999, 0.3175715658827539, 0.501172251963533, 1.25390138653177, -0.5927412976573511, -1.2860731142401598, 0.19212255375428502, -0.23180140440867997, 0.0438679026550234, 0.0310655693522602, -0.0278301067095114, 0.0190692820705961, -0.743953263847003, 0.551383640341839, 0.95247900191939, -0.0753260867506019, -0.19527783570531498, -0.244890838405177, -0.568486042635007, -0.193055947193404, 0.0579216247716934, 0.169036074354479, -0.0296032833210453, 0.912794608837024, 0.592879492735213, -0.3597387783166529, 0.00929082729555871, 0.0252009351546255, -0.31664690429229125], 0]\n",
      "[[2.004682046993, -1.2410879735476399, 0.44875708401897296, -0.593415890059677, -1.7884840534410802, -0.29129183354050503, -1.5767143886259698, -0.0794065302435994, 1.7649297009497902, 0.277675075263534, -0.0455668092653409, -2.01975049353515, 3.15854649560171, 0.5828450510444471, -0.00298243263280276, -0.7028543947615121, 0.272012930246687, 1.7209935293743202, -1.2443121529228, -0.420836083706302, -0.291734479072225, -0.0105338076434743, 0.30778998716404804, -0.0157288365366745, -0.8171891991697091, 1.2022211329606598, -0.0479146173126854, -0.0353823166029543, -0.10974594375600207], 0]\n",
      "[[2.2186852503485697, -0.588027128312842, -2.5535469902917405, -1.0292697327297802, 0.334785878824552, -1.23925807845064, 0.333539504979431, -0.4529439007622071, -1.23423618630854, 1.11324182722431, 0.888516325465505, -0.36079055253466097, -0.827230714330475, 0.758414885875982, -1.1276806409166298, 0.301670399907482, 0.331209554023249, -1.16339682547686, 1.0344839605371, -0.0320352060904944, 0.531920433913029, 1.4711834840962499, -0.21307631413122305, 0.850090512241537, 0.7187947502812941, 0.24405407275862698, -0.112541096667752, -0.0932874843890836, -0.21729446237293307], 0]\n",
      "[[0.27817949572767897, -0.41924138911163794, -0.187753789473277, -2.48154501699571, 2.0122433077809503, 3.91974823366381, -0.44721479670342795, 0.853152972573788, -0.7340905499222959, 0.350445782255484, -0.35714925701168204, -0.328613553128114, 0.0791047801518888, -0.32986832245017306, 0.36988915533378497, -1.22414912271851, -0.544498461267149, 0.832268475756288, -1.1154816753367098, -0.39432679792887504, -0.598768649703635, -1.1824645799302, 0.284212044878714, 0.638238357115995, -0.9975981105996411, 0.151798893986414, -0.0869334174357996, -0.17302237826157701, -0.2892999947257557], 0]\n",
      "[[-2.2266595057865697, 2.03340016013175, 1.9077641252209698, 0.5978369658398149, -0.411783761548827, 0.34108103444214, -0.00602462518153499, -1.95879646359212, 0.6074498938128651, 1.3840973386066002, 0.510774052010156, 0.718625259561259, 1.2213720606257599, -0.8464654498773609, 1.7337654866776002, -0.5574809668974661, -0.10992635528107401, -0.5271388537362279, -0.182068295378308, -0.116288117643231, 1.47976845022868, -0.238264365574385, 0.0543604067907351, 0.366896517818576, 0.06940046586167001, -0.580882381168515, -1.80050693020546, -1.12009901066076, -0.313248531027444], 0]\n",
      "[[-0.36780500075478395, 0.0179773434110245, 1.71821307329829, -0.9607334119408829, 0.0500229791019851, 0.0698879824656404, 0.367615761520485, -0.514582037189781, -1.1307931511095801, 0.9939661202130291, -0.21678185773571598, -0.882044972425486, 0.8082973124659609, -0.7899618180710329, 1.46879633536226, 0.412098972792812, 0.419729630222546, -1.69904448391567, 1.61467416273574, 0.33194265465611605, -0.0909153999626666, 0.00901889889004731, -0.145675694109701, -0.44536839312060794, -0.49156096450851894, -0.40110096533033796, -0.40947097382028497, -0.298264039062785, -0.17255587786276735], 0]\n",
      "[[2.34739139164081, -1.16504842863814, -1.7517727655711002, -1.9229301966422099, -0.433431156453596, -0.474613863954195, -0.7204388752339351, -0.187132291674565, -1.9250965704227299, 1.84495620508657, 0.393760130133495, -0.5640715522721321, 0.0829524994902375, 0.232628635980413, -0.493568719220541, -0.25730300475724, 0.013237820330067, 0.319403931260466, 0.411045484110936, -0.413290463072665, -0.305382966446122, -0.5501672562117099, 0.259074060911496, 0.137586293191048, -0.129436505160437, -0.332237295492422, -0.0340490224640307, -0.0666704403513597, -0.29845561210987354], 0]\n",
      "[[1.3290701317624098, -0.51310901781562, 0.45502659363242404, -0.6922047510244079, -1.0528680659729102, -0.712141532476583, -0.5265150420487771, -0.0988704015659158, -1.1397322831765, 0.833186869117116, 1.26321298562295, 0.6759587774079301, 0.48867239568315707, 0.23409536442736603, 0.244429139605552, -0.9903931618697651, -0.339405514925081, 1.32395788980117, -0.4740981538362701, -0.4251934341233689, -0.427668211628875, -0.8171152461482571, 0.119061325775619, 0.355772338280885, 0.0706622425692906, 0.8847562508655441, -0.0592144795110054, 0.00338445884751446, -0.2809839754423647], 0]\n",
      "[[-0.27536353459735696, 1.3242554236625201, -3.02974323573341, -1.30025879283394, 4.16110504072626, 2.67148285099847, 0.707509168980743, -0.14284435380191798, -0.7768748987140469, -1.6558246861757902, 0.587680310019223, -0.650565353620265, -0.717663009121341, -2.25490274707113, -0.0327320898261017, 0.250901972349705, 2.09572404424035, 0.563699907199745, -0.611317310663516, -0.217397987445764, 0.7561055130238991, -0.236595905319226, -0.28209894666725105, 0.514410011999066, 0.3146184465575, 0.6969719651561209, 0.0656864799565053, 0.0768563059324797, -0.3501908474594307], 0]\n",
      "[[-0.319250654882172, 0.9927126324444109, 0.8404324964601729, -0.20617013112134602, 0.608318891968772, 0.0241674174767472, 0.56286525705414, 0.174280052549063, -0.206680767831863, -0.5312382750633821, -0.9998529824051079, -0.758253503349262, -0.566319193915506, -0.29290408318654, 1.30831852166355, 0.412334244242137, -0.0181309337302664, -0.168199731676387, -0.0787463846509138, 0.0635100192986518, -0.308544802636534, -0.82183414653559, -0.0913797392586329, -0.971731432176279, -0.131583367169513, 0.164465468687089, 0.254841109697785, 0.0833692858675062, -0.3337986940642851], 0]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-18bb1d5335d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m#X_batch, y_batch = X_batch.to(\"cpu\"), y_batch.to(\"cpu\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, num_epochs+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        #X_batch, y_batch = X_batch.to(\"cpu\"), y_batch.to(\"cpu\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1).float())\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "\n",
    "#torch.save(model.state_dict(), './credit_card_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-10e318238336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'labels'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        #print(X_batch)\n",
    "        y_test_pred = model(X_batch[0])\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56875\n",
      "           1       0.93      0.62      0.74        87\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.81      0.87     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56871,     4],\n",
       "       [   33,    54]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
